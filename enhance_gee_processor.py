#!/usr/bin/env python3
"""
å¢å¼ºGEEå¤„ç†å™¨ä»¥æ”¯æŒçœŸå®æ•°æ®é›†
æ”¯æŒNuminaæ•°å­¦æ¨ç†æ•°æ®å’Œå…¶ä»–çœŸå®æ•°æ®æº
"""
import pandas as pd
import numpy as np
from pathlib import Path
import json
import re
import sys
sys.path.append('.')

from dataset.gee_processor import GEEProcessor

class EnhancedGEEProcessor(GEEProcessor):
    """å¢å¼ºç‰ˆGEEå¤„ç†å™¨ï¼Œæ”¯æŒå¤šç§çœŸå®æ•°æ®æº"""
    
    def __init__(self, tokenizer):
        super().__init__(tokenizer)
        self.name_patterns = {
            'male': ['Tom', 'John', 'Mike', 'Bob', 'David', 'James', 'Robert', 'Michael', 'William', 'Richard'],
            'female': ['Sarah', 'Lisa', 'Emma', 'Alice', 'Mary', 'Jennifer', 'Linda', 'Elizabeth', 'Barbara', 'Susan']
        }
    
    def process_numina_data(self, file_path: str, target_size: int = 1000) -> list:
        """å¤„ç†Numinaæ•°å­¦æ¨ç†æ•°æ®"""
        print(f"ğŸ“Š å¤„ç†Numinaæ•°æ®: {file_path}")
        
        # è¯»å–parquetæ–‡ä»¶
        df = pd.read_parquet(file_path)
        print(f"åŸå§‹æ•°æ®é‡: {len(df)}")
        
        # éšæœºé‡‡æ ·
        if len(df) > target_size:
            df = df.sample(n=target_size, random_state=42)
            print(f"é‡‡æ ·åæ•°æ®é‡: {len(df)}")
        
        processed_data = []
        for idx, row in df.iterrows():
            # æå–é—®é¢˜å’Œç­”æ¡ˆ
            problem = row.get('problem', row.get('question', ''))
            solution = row.get('solution', row.get('answer', ''))
            
            if problem and solution:
                # ç”Ÿæˆæ€§åˆ«å¹³è¡¡çš„å˜ä½“
                male_version = self._genderize_text(problem, 'male')
                female_version = self._genderize_text(problem, 'female')
                
                processed_data.extend([
                    {
                        'input': self.apply_chat_template(male_version),
                        'output': solution,
                        'gender': 'male',
                        'original_id': idx,
                        'source': 'numina'
                    },
                    {
                        'input': self.apply_chat_template(female_version), 
                        'output': solution,
                        'gender': 'female',
                        'original_id': idx,
                        'source': 'numina'
                    }
                ])
        
        print(f"âœ… å¤„ç†å®Œæˆï¼Œç”Ÿæˆ {len(processed_data)} ä¸ªæ ·æœ¬")
        return processed_data
    
    def process_1shot_rlvr_data(self, file_path: str) -> list:
        """å¤„ç†1shot RLVRæ•°æ®"""
        print(f"ï¿½ï¿½ å¤„ç†1shot RLVRæ•°æ®: {file_path}")
        
        df = pd.read_parquet(file_path)
        print(f"åŸå§‹æ•°æ®é‡: {len(df)}")
        
        processed_data = []
        for idx, row in df.iterrows():
            # æ ¹æ®å®é™…æ•°æ®ç»“æ„è°ƒæ•´
            prompt = row.get('prompt', row.get('input', ''))
            
            if prompt:
                # ç”Ÿæˆæ€§åˆ«å˜ä½“
                for gender in ['male', 'female']:
                    genderized_prompt = self._genderize_text(prompt, gender)
                    
                    processed_data.append({
                        'input': self.apply_chat_template(genderized_prompt),
                        'gender': gender,
                        'original_id': idx,
                        'source': '1shot_rlvr'
                    })
        
        print(f"âœ… å¤„ç†å®Œæˆï¼Œç”Ÿæˆ {len(processed_data)} ä¸ªæ ·æœ¬")
        return processed_data
    
    def _genderize_text(self, text: str, target_gender: str) -> str:
        """å°†æ–‡æœ¬ä¸­çš„æ€§åˆ«å¼•ç”¨è½¬æ¢ä¸ºæŒ‡å®šæ€§åˆ«"""
        
        # é€‰æ‹©åå­—
        names = self.name_patterns[target_gender]
        
        # æ›¿æ¢é€šç”¨å ä½ç¬¦
        if '[NAME]' in text or '{name}' in text:
            name = np.random.choice(names)
            text = text.replace('[NAME]', name).replace('{name}', name)
            return text
        
        # æ£€æµ‹ç°æœ‰æ€§åˆ«åå­—å¹¶æ›¿æ¢
        all_male_names = self.name_patterns['male']
        all_female_names = self.name_patterns['female'] 
        
        for male_name in all_male_names:
            if male_name in text:
                replacement = np.random.choice(names)
                text = text.replace(male_name, replacement)
                break
                
        for female_name in all_female_names:
            if female_name in text:
                replacement = np.random.choice(names)
                text = text.replace(female_name, replacement)
                break
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åå­—ï¼Œéšæœºæ·»åŠ ä¸€ä¸ª
        if not any(name in text for name in all_male_names + all_female_names):
            name = np.random.choice(names)
            # åœ¨åˆé€‚çš„åœ°æ–¹æ’å…¥åå­—
            if "person" in text.lower():
                text = text.replace("person", name)
            elif "student" in text.lower():
                text = text.replace("student", f"student named {name}")
            elif "someone" in text.lower():
                text = text.replace("someone", name)
            else:
                # åœ¨å¥å­å¼€å¤´æ·»åŠ 
                text = f"{name} is working on this problem: {text}"
        
        return text
    
    def create_balanced_dataset(self, data_sources: list, balance_method: str = 'oversample') -> list:
        """åˆ›å»ºæ€§åˆ«å¹³è¡¡çš„æ•°æ®é›†"""
        
        all_data = []
        for source_config in data_sources:
            source_type = source_config['type']
            file_path = source_config['path']
            
            if source_type == 'numina':
                data = self.process_numina_data(file_path, source_config.get('target_size', 1000))
            elif source_type == '1shot_rlvr':
                data = self.process_1shot_rlvr_data(file_path)
            else:
                print(f"âš ï¸ æœªçŸ¥æ•°æ®æºç±»å‹: {source_type}")
                continue
                
            all_data.extend(data)
        
        # ç»Ÿè®¡æ€§åˆ«åˆ†å¸ƒ
        male_data = [item for item in all_data if item['gender'] == 'male']
        female_data = [item for item in all_data if item['gender'] == 'female']
        
        print(f"\nğŸ“Š åŸå§‹æ•°æ®åˆ†å¸ƒ:")
        print(f"   ç”·æ€§æ ·æœ¬: {len(male_data)}")
        print(f"   å¥³æ€§æ ·æœ¬: {len(female_data)}")
        
        # å¹³è¡¡å¤„ç†
        if balance_method == 'oversample':
            target_size = max(len(male_data), len(female_data))
            
            if len(male_data) < target_size:
                male_data = male_data * (target_size // len(male_data)) + male_data[:target_size % len(male_data)]
            if len(female_data) < target_size:
                female_data = female_data * (target_size // len(female_data)) + female_data[:target_size % len(female_data)]
                
        elif balance_method == 'undersample':
            target_size = min(len(male_data), len(female_data))
            male_data = male_data[:target_size]
            female_data = female_data[:target_size]
        
        balanced_data = male_data + female_data
        np.random.shuffle(balanced_data)
        
        print(f"ğŸ“Š å¹³è¡¡åæ•°æ®åˆ†å¸ƒ:")
        male_count = sum(1 for item in balanced_data if item['gender'] == 'male')
        female_count = sum(1 for item in balanced_data if item['gender'] == 'female')
        print(f"   ç”·æ€§æ ·æœ¬: {male_count}")
        print(f"   å¥³æ€§æ ·æœ¬: {female_count}")
        print(f"   æ€»æ ·æœ¬æ•°: {len(balanced_data)}")
        
        return balanced_data

def main():
    """ç¤ºä¾‹ç”¨æ³•"""
    from transformers import AutoTokenizer
    
    print("ğŸ”§ æµ‹è¯•å¢å¼ºç‰ˆGEEå¤„ç†å™¨...")
    
    # åˆå§‹åŒ–
    tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen2.5-Math-1.5B-Instruct", trust_remote_code=True)
    processor = EnhancedGEEProcessor(tokenizer)
    
    # é…ç½®æ•°æ®æº
    data_sources = [
        {
            'type': 'numina',
            'path': 'dataset/numina/numina_00.parquet',
            'target_size': 100  # æµ‹è¯•ç”¨å°æ ·æœ¬
        }
        # å¯ä»¥æ·»åŠ æ›´å¤šæ•°æ®æº
    ]
    
    # å¤„ç†æ•°æ®
    try:
        balanced_data = processor.create_balanced_dataset(data_sources, balance_method='oversample')
        
        # ä¿å­˜ç»“æœ
        output_file = 'enhanced_training_data.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(balanced_data, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… å¢å¼ºæ•°æ®å·²ä¿å­˜: {output_file}")
        
        # æ˜¾ç¤ºç¤ºä¾‹
        print(f"\nğŸ“ æ•°æ®ç¤ºä¾‹:")
        for i, sample in enumerate(balanced_data[:4]):
            print(f"  ç¤ºä¾‹ {i+1} ({sample['gender']}):")
            print(f"    è¾“å…¥: {sample['input'][:100]}...")
            print()
            
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")

if __name__ == "__main__":
    main()
