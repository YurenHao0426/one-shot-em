#!/bin/bash
# çº¯åè§å‡å°‘è®­ç»ƒè„šæœ¬
# ç›®æ ‡ï¼šåªæœ€å°åŒ–ç”·å¥³é—´ç†µå·®ï¼Œä¸è¿›è¡Œæ•´ä½“ç†µæœ€å°åŒ–

echo "ğŸ¯ å¼€å§‹çº¯åè§å‡å°‘è®­ç»ƒ"
echo "ç›®æ ‡ï¼šæœ€å°åŒ– |H_female - H_male|"
echo "ç‰¹ç‚¹ï¼šä¸åŒ…å«ç†µæœ€å°åŒ–(EM)ï¼Œä¸“æ³¨debiasing"

# é»˜è®¤å‚æ•°
MODEL_PATH=${1:-"Qwen2.5-Math-1.5B-Instruct"}
RUN_NAME=${2:-"pure_debiasing_$(date +%m%d_%H%M)"}
TARGET_GAP=${3:-0.01}
MAX_STEPS=${4:-20}

echo ""
echo "ğŸ“Š é…ç½®ä¿¡æ¯:"
echo "   æ¨¡å‹è·¯å¾„: $MODEL_PATH"
echo "   è¿è¡Œåç§°: $RUN_NAME"
echo "   ç›®æ ‡ç†µå·®: $TARGET_GAP"
echo "   æœ€å¤§æ­¥æ•°: $MAX_STEPS"
echo ""

# æ£€æŸ¥æ¨¡å‹è·¯å¾„
if [ ! -d "$MODEL_PATH" ]; then
    echo "âŒ é”™è¯¯: æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: $MODEL_PATH"
    echo "è¯·æä¾›æ­£ç¡®çš„æ¨¡å‹è·¯å¾„ä½œä¸ºç¬¬ä¸€ä¸ªå‚æ•°"
    echo "ç”¨æ³•: $0 <model_path> [run_name] [target_gap] [max_steps]"
    exit 1
fi

# è¿è¡Œçº¯åè§å‡å°‘è®­ç»ƒ
python train_debiasing.py \
    --model_path "$MODEL_PATH" \
    --run_name "$RUN_NAME" \
    --target_gap $TARGET_GAP \
    --max_steps $MAX_STEPS \
    --micro_batch_size 2 \
    --effective_batch 4 \
    --learning_rate 1e-5 \
    --scale_factor 1.0 \
    --use_test_data \
    --wandb_project "pure-debiasing" \
    --log_steps 1 \
    --save_steps 10

echo ""
echo "ğŸ‰ çº¯åè§å‡å°‘è®­ç»ƒå®Œæˆï¼"
echo "ğŸ“ æ£€æŸ¥ç‚¹ä¿å­˜åœ¨: checkpoints/$(basename $MODEL_PATH)/$RUN_NAME/"
echo "ï¿½ï¿½ æŸ¥çœ‹WandBæ—¥å¿—äº†è§£è¯¦ç»†è®­ç»ƒè¿‡ç¨‹" 