# çº¯åè§å‡å°‘(Pure Debiasing)ä½¿ç”¨æŒ‡å—

## ğŸ¯ æ¦‚è¿°

çº¯åè§å‡å°‘è®­ç»ƒä¸“æ³¨äº**æœ€å°åŒ–ç”·å¥³é—´çš„ç†µå·®**ï¼Œä¸åŒ…å«æ•´ä½“ç†µæœ€å°åŒ–(EM)ã€‚è¿™ä½¿å¾—è®­ç»ƒç›®æ ‡æ›´åŠ æ˜ç¡®ï¼Œè®¡ç®—æ›´åŠ é«˜æ•ˆã€‚

### æ ¸å¿ƒç›®æ ‡
```
åŸGEEæŸå¤±: L = HÌ„ + Î» * (H_female - H_male)Â²
          â†“
çº¯Debiasing: L = (H_female - H_male)Â²
```

**å…³é”®ä¼˜åŠ¿:**
- âœ… ç›®æ ‡æ›´æ˜ç¡®ï¼šåªå…³æ³¨æ€§åˆ«åè§
- âœ… è®¡ç®—æ›´ç®€å•ï¼šå»é™¤ç†µæœ€å°åŒ–é¡¹
- âœ… è®­ç»ƒæ›´ç¨³å®šï¼šå•ä¸€ä¼˜åŒ–ç›®æ ‡
- âœ… æ•ˆæœæ›´ç›´æ¥ï¼šç†µå·®è·ç›´æ¥ä¸‹é™

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. åŸºç¡€è¿è¡Œ
```bash
# ä½¿ç”¨é»˜è®¤å‚æ•°
./scripts/run_pure_debiasing.sh /path/to/your/model

# è‡ªå®šä¹‰å‚æ•°
./scripts/run_pure_debiasing.sh /path/to/model my_run_name 0.005 30
```

### 2. æ‰‹åŠ¨è¿è¡Œ
```bash
python train_debiasing.py \
    --model_path /path/to/model \
    --run_name pure_debiasing_test \
    --target_gap 0.01 \
    --max_steps 20 \
    --micro_batch_size 2 \
    --effective_batch 4 \
    --learning_rate 1e-5 \
    --use_test_data
```

## ğŸ“Š æ ¸å¿ƒç»„ä»¶

### 1. æŸå¤±å‡½æ•° (`losses/debiasing_loss.py`)
```python
class DebiasingLoss:
    def __init__(self, use_l1=False, scale_factor=1.0):
        """
        use_l1: False=L2æŸå¤±, True=L1æŸå¤±
        scale_factor: æŸå¤±ç¼©æ”¾å› å­
        """
```

**æŸå¤±è®¡ç®—:**
- L2ç‰ˆæœ¬: `(H_female - H_male)Â²`
- L1ç‰ˆæœ¬: `|H_female - H_male|`

### 2. è®­ç»ƒè„šæœ¬ (`train_debiasing.py`)
ä¸“é—¨çš„çº¯debiasingè®­ç»ƒï¼ŒåŒ…å«ï¼š
- æ™ºèƒ½æ‰¹æ¬¡å¹³è¡¡
- æ—©åœæœºåˆ¶(è¾¾åˆ°ç›®æ ‡ç†µå·®)
- å®æ—¶ç›‘æ§å’Œå¯è§†åŒ–

### 3. æµ‹è¯•éªŒè¯
```bash
# æ•°å­¦é€»è¾‘æµ‹è¯•
python test_debiasing_math.py

# å®Œæ•´åŠŸèƒ½æµ‹è¯•(éœ€è¦PyTorch)
python test_debiasing_loss.py
```

## ğŸ”§ å‚æ•°é…ç½®

### å…³é”®å‚æ•°
| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--target_gap` | 0.01 | ç›®æ ‡ç†µå·®è·ï¼Œè¾¾åˆ°åæ—©åœ |
| `--scale_factor` | 1.0 | æŸå¤±ç¼©æ”¾å› å­ |
| `--use_l1` | False | ä½¿ç”¨L1æŸå¤±æ›¿ä»£L2 |
| `--learning_rate` | 1e-5 | å­¦ä¹ ç‡(å»ºè®®è¾ƒä½) |
| `--micro_batch_size` | 2 | å¿…é¡»â‰¥2ä¿è¯æ€§åˆ«å¹³è¡¡ |

### è®­ç»ƒå»ºè®®
- **å­¦ä¹ ç‡**: 1e-5 åˆ° 5e-5 (æ¯”æ™®é€šè®­ç»ƒæ›´ä½)
- **æ‰¹æ¬¡å¤§å°**: ç¡®ä¿æ¯æ‰¹è‡³å°‘1ç”·1å¥³
- **ç›®æ ‡ç†µå·®**: 0.005-0.02 (æ ¹æ®åº”ç”¨éœ€æ±‚è°ƒæ•´)
- **è®­ç»ƒæ­¥æ•°**: é€šå¸¸10-50æ­¥å³å¯çœ‹åˆ°æ•ˆæœ

## ğŸ“ˆ ç›‘æ§æŒ‡æ ‡

è®­ç»ƒè¿‡ç¨‹ä¸­å…³é”®æŒ‡æ ‡ï¼š
```
ğŸ“‰ Step 1 | loss=0.160000 | gap=0.400000 | H_male=0.4500 | H_female=0.8500
ğŸ“‰ Step 2 | loss=0.040000 | gap=0.200000 | H_male=0.5000 | H_female=0.7000
ğŸ“‰ Step 3 | loss=0.010000 | gap=0.100000 | H_male=0.5500 | H_female=0.6500
```

**ç†æƒ³è®­ç»ƒè½¨è¿¹:**
- æŸå¤±æŒç»­ä¸‹é™
- ç†µå·®è·(`gap`)æŒç»­ç¼©å°
- `H_male`å’Œ`H_female`è¶‹äºç›¸ç­‰

## ğŸ¯ é¢„æœŸæ•ˆæœ

### è®­ç»ƒå‰
```
H_male=0.25, H_female=0.95, gap=0.70 (ä¸¥é‡åè§ ğŸ’¥)
```

### è®­ç»ƒå
```
H_male=0.58, H_female=0.60, gap=0.02 (è½»å¾®åè§ âš ï¸)
```

### ç†æƒ³çŠ¶æ€
```
H_male=0.60, H_female=0.60, gap=0.00 (æ— åè§ âœ…)
```

## ğŸ”„ ä¸åŸGEEçš„å¯¹æ¯”

| æ–¹é¢ | åŸGEE | çº¯Debiasing |
|------|-------|-------------|
| æŸå¤±å‡½æ•° | `HÌ„ + Î»*(H_f-H_m)Â²` | `(H_f-H_m)Â²` |
| ä¼˜åŒ–ç›®æ ‡ | ç†µæœ€å°åŒ–+åè§å‡å°‘ | ä»…åè§å‡å°‘ |
| å‚æ•°æ•°é‡ | éœ€è¦è°ƒèŠ‚Î»æƒé‡ | æ— éœ€æƒé‡è°ƒèŠ‚ |
| è®­ç»ƒå¤æ‚åº¦ | é«˜(åŒç›®æ ‡å¹³è¡¡) | ä½(å•ç›®æ ‡) |
| æ”¶æ•›é€Ÿåº¦ | è¾ƒæ…¢ | è¾ƒå¿« |
| åè§å‡å°‘æ•ˆæœ | å¯èƒ½è¢«EMç›®æ ‡ç¨€é‡Š | ç›´æ¥ä¸”å¼ºçƒˆ |

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. æ•°æ®å‡†å¤‡
```python
# ç¡®ä¿æ•°æ®æ€§åˆ«å¹³è¡¡
male_samples = [s for s in data if s['gender'] == 'male']
female_samples = [s for s in data if s['gender'] == 'female']
print(f"ç”·å¥³æ¯”ä¾‹: {len(male_samples)}:{len(female_samples)}")
```

### 2. è¶…å‚è°ƒä¼˜
```bash
# ä¿å®ˆè®¾ç½®(ç¨³å®šä½†æ…¢)
--learning_rate 5e-6 --target_gap 0.005

# æ¿€è¿›è®¾ç½®(å¿«é€Ÿä½†å¯èƒ½ä¸ç¨³å®š)
--learning_rate 2e-5 --target_gap 0.02
```

### 3. ç›‘æ§è¦ç‚¹
- å…³æ³¨`entropy_gap`æ˜¯å¦æŒç»­ä¸‹é™
- æ£€æŸ¥æ‰¹æ¬¡å¹³è¡¡æ€§(æ— è­¦å‘Šä¿¡æ¯)
- è§‚å¯ŸæŸå¤±æ”¶æ•›æ›²çº¿

### 4. æ•…éšœæ’é™¤
```bash
# å¦‚æœæ‰¹æ¬¡ä¸å¹³è¡¡
--micro_batch_size 4  # å¢åŠ æ‰¹æ¬¡å¤§å°

# å¦‚æœè®­ç»ƒä¸ç¨³å®š
--learning_rate 1e-6  # é™ä½å­¦ä¹ ç‡

# å¦‚æœæ”¶æ•›å¤ªæ…¢
--scale_factor 2.0    # å¢åŠ æŸå¤±æƒé‡
```

## ğŸ“ æ–‡ä»¶ç»“æ„

```
losses/
â”œâ”€â”€ debiasing_loss.py        # çº¯debiasingæŸå¤±å‡½æ•°
â””â”€â”€ gee_loss.py             # åŸGEEæŸå¤±(å¯¹æ¯”ç”¨)

train_debiasing.py          # çº¯debiasingè®­ç»ƒè„šæœ¬
test_debiasing_math.py      # æ•°å­¦é€»è¾‘æµ‹è¯•
scripts/
â””â”€â”€ run_pure_debiasing.sh   # ä¾¿æ·è¿è¡Œè„šæœ¬
```

## ğŸ‰ æ€»ç»“

çº¯åè§å‡å°‘æ–¹æ³•æä¾›äº†ä¸€ä¸ª**æ›´ä¸“æ³¨ã€æ›´é«˜æ•ˆ**çš„debiasingè§£å†³æ–¹æ¡ˆã€‚é€šè¿‡å»é™¤ç†µæœ€å°åŒ–çš„å¹²æ‰°ï¼Œè®­ç»ƒè¿‡ç¨‹æ›´åŠ ç›´æ¥ï¼Œæ•ˆæœæ›´åŠ æ˜æ˜¾ã€‚

**é€‚ç”¨åœºæ™¯:**
- åªå…³å¿ƒå‡å°‘æ€§åˆ«åè§ï¼Œä¸éœ€è¦æ•´ä½“æ€§èƒ½ä¼˜åŒ–
- éœ€è¦å¿«é€ŸåŸå‹éªŒè¯debiasingæ•ˆæœ
- èµ„æºæœ‰é™çš„ç¯å¢ƒä¸‹è¿›è¡Œåè§å‡å°‘

**ä¸‹ä¸€æ­¥:** æ ¹æ®ä½ çš„å…·ä½“éœ€æ±‚è°ƒæ•´å‚æ•°ï¼Œå¼€å§‹çº¯debiasingè®­ç»ƒï¼ 