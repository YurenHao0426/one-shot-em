#!/usr/bin/env python3
"""
å¹³è¡¡çš„æ•°æ®åŠ è½½å™¨ - ç¡®ä¿æ¯ä¸ªæ‰¹æ¬¡åŒ…å«ç”·å¥³æ ·æœ¬
"""
import torch
from torch.utils.data import Dataset, DataLoader
import random
from typing import List, Dict

class BalancedGEEDataset(Dataset):
    def __init__(self, data: List[Dict]):
        self.data = data
        # æŒ‰æ€§åˆ«åˆ†ç»„
        self.male_data = [item for item in data if item['gender'] == 'male']
        self.female_data = [item for item in data if item['gender'] == 'female']
        
        print(f"ğŸ“Š æ•°æ®åˆ†å¸ƒ: male={len(self.male_data)}, female={len(self.female_data)}")
        
        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®
        if len(self.male_data) == 0 or len(self.female_data) == 0:
            raise ValueError("æ•°æ®ä¸­å¿…é¡»åŒ…å«ç”·æ€§å’Œå¥³æ€§æ ·æœ¬")
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        return self.data[idx]
    
    def create_balanced_batches(self, batch_size: int, num_batches: int = None):
        """åˆ›å»ºå¹³è¡¡çš„æ‰¹æ¬¡"""
        if batch_size < 2:
            raise ValueError("batch_sizeå¿…é¡»>=2æ‰èƒ½ä¿è¯æ€§åˆ«å¹³è¡¡")
        
        # æ¯ä¸ªæ‰¹æ¬¡ä¸­ç”·å¥³æ ·æœ¬çš„æ•°é‡
        male_per_batch = batch_size // 2
        female_per_batch = batch_size - male_per_batch
        
        batches = []
        max_batches = num_batches or (len(self.data) // batch_size)
        
        for i in range(max_batches):
            batch = []
            
            # éšæœºé€‰æ‹©ç”·æ€§æ ·æœ¬
            male_samples = random.sample(self.male_data, 
                                       min(male_per_batch, len(self.male_data)))
            batch.extend(male_samples)
            
            # éšæœºé€‰æ‹©å¥³æ€§æ ·æœ¬
            female_samples = random.sample(self.female_data, 
                                         min(female_per_batch, len(self.female_data)))
            batch.extend(female_samples)
            
            # æ‰“ä¹±æ‰¹æ¬¡å†…çš„é¡ºåº
            random.shuffle(batch)
            batches.append(batch)
            
            print(f"æ‰¹æ¬¡ {i+1}: male={len(male_samples)}, female={len(female_samples)}")
        
        return batches

def balanced_collate(batch, verbose=False):
    """å¹³è¡¡çš„collateå‡½æ•°"""
    inputs = [item["input"] for item in batch]
    genders = [item["gender"] for item in batch]
    
    # æ£€æŸ¥æ‰¹æ¬¡å¹³è¡¡æ€§
    male_count = sum(1 for g in genders if g == 'male')
    female_count = sum(1 for g in genders if g == 'female')
    
    if verbose:
        print(f"ğŸ” æ‰¹æ¬¡æ£€æŸ¥: male={male_count}, female={female_count}")
    
    # åªåœ¨ä¸å¹³è¡¡æ—¶æ‰“å°è­¦å‘Š
    if male_count == 0:
        print("âš ï¸ è­¦å‘Š: æ‰¹æ¬¡ä¸­æ²¡æœ‰ç”·æ€§æ ·æœ¬ï¼")
    if female_count == 0:
        print("âš ï¸ è­¦å‘Š: æ‰¹æ¬¡ä¸­æ²¡æœ‰å¥³æ€§æ ·æœ¬ï¼")
    
    return {
        "input": inputs,
        "gender": genders
    }

class BalancedDataLoader:
    """è‡ªå®šä¹‰å¹³è¡¡æ•°æ®åŠ è½½å™¨"""
    def __init__(self, balanced_batches):
        self.batches = balanced_batches
        self.current_idx = 0
    
    def __iter__(self):
        self.current_idx = 0
        return self
    
    def __next__(self):
        if self.current_idx >= len(self.batches):
            raise StopIteration
        
        batch = self.batches[self.current_idx]
        self.current_idx += 1
        
        # åº”ç”¨collateå‡½æ•° (ä¸æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ï¼Œåªæ˜¾ç¤ºè­¦å‘Š)
        return balanced_collate(batch, verbose=False)

def create_balanced_dataloader(data: List[Dict], batch_size: int, num_batches: int = 10):
    """åˆ›å»ºå¹³è¡¡çš„æ•°æ®åŠ è½½å™¨ - ä¿®å¤ç‰ˆæœ¬"""
    dataset = BalancedGEEDataset(data)
    
    if batch_size < 2:
        print("âš ï¸ è­¦å‘Š: batch_size < 2ï¼Œæ— æ³•ä¿è¯æ€§åˆ«å¹³è¡¡")
        return DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=lambda batch: balanced_collate(batch, verbose=True))
    
    # ğŸ”§ ä¿®å¤: ç›´æ¥è¿”å›é¢„æ„é€ çš„å¹³è¡¡æ‰¹æ¬¡
    balanced_batches = dataset.create_balanced_batches(batch_size, num_batches)
    
    print(f"âœ… åˆ›å»ºäº† {len(balanced_batches)} ä¸ªå¹³è¡¡æ‰¹æ¬¡")
    
    return BalancedDataLoader(balanced_batches)

# æµ‹è¯•å‡½æ•°
if __name__ == "__main__":
    # æµ‹è¯•å¹³è¡¡æ•°æ®åŠ è½½å™¨
    import sys
    sys.path.append('.')
    from dataset.gee_processor import GEEProcessor
    
    class MockTokenizer:
        def apply_chat_template(self, messages, tokenize=False, add_generation_prompt=True):
            return messages[0]["content"]
    
    processor = GEEProcessor(MockTokenizer())
    test_data = processor.create_test_data(num_samples=20)
    
    print("ğŸ§ª æµ‹è¯•ä¿®å¤åçš„å¹³è¡¡æ•°æ®åŠ è½½å™¨")
    dataloader = create_balanced_dataloader(test_data, batch_size=4, num_batches=3)
    
    for i, batch in enumerate(dataloader):
        print(f"\næ‰¹æ¬¡ {i+1}:")
        print(f"  è¾“å…¥æ•°é‡: {len(batch['input'])}")
        print(f"  æ€§åˆ«: {batch['gender']}")
        
        # éªŒè¯å¹³è¡¡æ€§
        male_count = sum(1 for g in batch['gender'] if g == 'male')
        female_count = sum(1 for g in batch['gender'] if g == 'female')
        
        if male_count > 0 and female_count > 0:
            print(f"  âœ… æ‰¹æ¬¡å¹³è¡¡: male={male_count}, female={female_count}")
        else:
            print(f"  âŒ æ‰¹æ¬¡ä¸å¹³è¡¡: male={male_count}, female={female_count}")
        
        if i >= 2:  # åªæµ‹è¯•å‰3ä¸ªæ‰¹æ¬¡
            break
    
    print("\nâœ… å¹³è¡¡æ•°æ®åŠ è½½å™¨æµ‹è¯•å®Œæˆ!") 